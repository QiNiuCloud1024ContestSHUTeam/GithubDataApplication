{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T03:44:45.564503600Z",
     "start_time": "2024-10-31T03:44:45.191806600Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 请求头\n",
    "TopicHeaders = {\n",
    "    'Cookie': '_octo=GH1.1.547050398.1730121222; _device_id=73a715dea9188e9052280e9ba8f00a3d; saved_user_sessions=124904356%3AFGDwEe-yLWPAB9iCFsxyTgm-Ij8frauGVZNDils0DyQ_FDi4; user_session=FGDwEe-yLWPAB9iCFsxyTgm-Ij8frauGVZNDils0DyQ_FDi4; __Host-user_session_same_site=FGDwEe-yLWPAB9iCFsxyTgm-Ij8frauGVZNDils0DyQ_FDi4; logged_in=yes; dotcom_user=yizhilsy; color_mode=%7B%22color_mode%22%3A%22auto%22%2C%22light_theme%22%3A%7B%22name%22%3A%22light%22%2C%22color_mode%22%3A%22light%22%7D%2C%22dark_theme%22%3A%7B%22name%22%3A%22dark%22%2C%22color_mode%22%3A%22dark%22%7D%7D; preferred_color_mode=light; tz=Asia%2FShanghai; _gh_sess=wgcGGu1teQcioqHPiWBCx0tVV%2BgI4OSl5S1WSmwI4%2BLlrg7DS2GFaw1Z%2BTJRYq4SKGHp%2Fm4b9ZkIfhQqgACyapyAa8XZtdkOIGF%2Fkk%2BTwIj9ibdWec5%2B8oofaPsQipgRe7Jmfv3LPdqazTY%2BxAj8IujwSpfd%2BSaJqI3QPiZucUbs%2FYPRwWQfcz7qWrb0%2Ftzbd0eeLfAQg75s1uxusz67iprHm%2Fl0rFU6ZOrzMB1Gl4uVPDXP%2FkOwpiCLFvgWUaKEgTAEy2C4T%2BMTFL285JZ1cDY1rM0TPhOkU89zIezfnw6YflOnC%2FE%2FhgRne3QOWKI1mAvd%2BleJNC3EE0nVhVZwC5I%2FQw0%2BuJGikotXbvSc0MWRrHsaD1Nen3gR6WAchiW6--2m9XRat%2B2oaDceNY--FmGSxVluLBuvzl1Y7CQe5A%3D%3D',\n",
    "    'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "    'X-Requested-With': 'XMLHttpRequest',\n",
    "    'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "    'Accept': 'text/html',\n",
    "    'Sec-Ch-Ua': '\"Not?A_Brand\";v=\"99\", \"Chromium\";v=\"130\"',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.6723.59 Safari/537.36',\n",
    "    'Sec-Ch-Ua-Mobile': '?0',\n",
    "    'Sec-Fetch-Site': 'same-origin',\n",
    "    'Sec-Fetch-Mode': 'cors',\n",
    "    'Sec-Fetch-Dest': 'empty',\n",
    "    'Referer': 'https://github.com/topics',\n",
    "    'Accept-Encoding': 'gzip, deflate, br'\n",
    "}\n",
    "def get_Topics(page):\n",
    "    # URL\n",
    "    url = 'https://github.com/topics?page={page}'.format(page = page)\n",
    "    response = requests.get(url, headers=TopicHeaders)\n",
    "    # 检查请求是否成功\n",
    "    if response.status_code == 200:\n",
    "        return response.text    # 返回 HTML 内容\n",
    "    else:\n",
    "        print(f\"请求失败，状态码：{response.status_code}\")\n",
    "        return None\n",
    "\n",
    "RepoHeaders = {'User-Agent': 'Mozilla/5.0',\n",
    "               'Authorization': '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',\n",
    "               'Content-Type': 'application/json',\n",
    "               'Accept': 'application/vnd.github.text-match+json'}\n",
    "# 获取topic搜索条件下的所有仓库\n",
    "def get_ReposByTopic(topic):\n",
    "    targetPath = './Repos/{}/AllReposUnder{}.json'.format(topic, topic)\n",
    "    \n",
    "    \n",
    "    repoItems_list = []\n",
    "    # 请求topic下的第一页数据\n",
    "    page = 1\n",
    "    per_page = 100\n",
    "    url = 'https://api.github.com/search/repositories?q=topic:{topic}&page={page}&per_page={per_page}&sort=stars&order=desc'.format(topic=topic, page = page,per_page = per_page)\n",
    "    req = Request(url, headers=RepoHeaders)\n",
    "    response = urlopen(req).read()\n",
    "    result = json.loads(response.decode())    \n",
    "    # 计算总条数以及总共需要请求的页数\n",
    "    total_count = result['total_count']\n",
    "    total_page = total_count // per_page + 1 \n",
    "    # 由于Github API限制，最多只能请求10页数据\n",
    "    total_page = min(10, total_page)\n",
    "    for item in result['items']:\n",
    "        repoItems_list.append(item)\n",
    "    \n",
    "    print(f\"topic: {topic}下的第{page}页数据已请求，共{total_page}页\")\n",
    "    time.sleep(7)\n",
    "    \n",
    "    # 后续页数的请求\n",
    "    for page in range(2,total_page+1):\n",
    "        url = 'https://api.github.com/search/repositories?q=topic:{topic}&page={page}&per_page={per_page}&sort=stars&order=desc'.format(topic=topic, page = page,per_page = per_page)\n",
    "        req = Request(url, headers=RepoHeaders)\n",
    "        response = urlopen(req).read()\n",
    "        result = json.loads(response.decode())\n",
    "        for item in result['items']:\n",
    "            repoItems_list.append(item)\n",
    "        print(f\"topic: {topic}下的第{page}页数据已请求，共{total_page}页\")\n",
    "        time.sleep(7)\n",
    "        \n",
    "    # 封装成字典\n",
    "    datadictionary = {'total_count': total_count, 'items': repoItems_list}\n",
    "    \n",
    "    # 将repoItems_list中的信息保存到本地json文件中\n",
    "    with open('./Repos/{}/AllReposUnder{}.json'.format(topic, topic), 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(datadictionary, json_file, ensure_ascii=False, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T09:56:13.331340300Z",
     "start_time": "2024-10-31T09:56:13.324079300Z"
    }
   },
   "id": "f3a22b3052520af2",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 获取所有官方topic的html文件（6页page）\n",
    "for page in range(1, 7):\n",
    "    topic_html = get_Topics(page)\n",
    "    with open(\"./topicPages/topics_page_{}.html\".format(page), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(topic_html)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T03:44:52.859163400Z",
     "start_time": "2024-10-31T03:44:45.566508300Z"
    }
   },
   "id": "d723293faa1998a8",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "# 读取爬取的html文件分割出官方topic字符串存入文件中\n",
    "# 设置文件目录\n",
    "directory = \"./topicPages/\"\n",
    "# 正则表达式模式\n",
    "pattern = r'<a href=\"/topics/(.*?)\"'\n",
    "topics_list = []\n",
    "for page in range(1, 7):\n",
    "    filename = f\"topics_page_{page}.html\"\n",
    "    filepath = os.path.join(directory, filename)\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "        # 查找所有匹配的字符串\n",
    "        matches = re.findall(pattern, content)\n",
    "        if matches:\n",
    "            matchesLen = len(matches)\n",
    "            for index in range(0, matchesLen, 2):\n",
    "                topics_list.append(matches[index])\n",
    "# 写入文件\n",
    "with open(\"./topicPages/govTopics.txt\", \"a\", encoding=\"utf-8\") as f:\n",
    "    count = 1\n",
    "    for topic in topics_list:\n",
    "        f.write(str(count) + \":\" + topic + \"\\n\")\n",
    "        count = count + 1\n",
    "print(count-1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T08:59:43.973904200Z",
     "start_time": "2024-10-31T08:59:43.945442900Z"
    }
   },
   "id": "7f76e7954265024c",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新文件夹 `./Repos\\3d` 已创建\n",
      "topic: 3d下的第1页数据已请求，共10页\n",
      "topic: 3d下的第2页数据已请求，共10页\n",
      "topic: 3d下的第3页数据已请求，共10页\n",
      "topic: 3d下的第4页数据已请求，共10页\n",
      "topic: 3d下的第5页数据已请求，共10页\n",
      "topic: 3d下的第6页数据已请求，共10页\n",
      "topic: 3d下的第7页数据已请求，共10页\n",
      "topic: 3d下的第8页数据已请求，共10页\n",
      "topic: 3d下的第9页数据已请求，共10页\n",
      "topic: 3d下的第10页数据已请求，共10页\n",
      "3d的仓库信息已保存至: ./Repos\\3d\n",
      "新文件夹 `./Repos\\ajax` 已创建\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mHTTPError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[53], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m os\u001B[38;5;241m.\u001B[39mmakedirs(folder_path,exist_ok\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m新文件夹 `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` 已创建\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 12\u001B[0m get_ReposByTopic(govTopic)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgovTopic\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m的仓库信息已保存至: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfolder_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[50], line 40\u001B[0m, in \u001B[0;36mget_ReposByTopic\u001B[1;34m(topic)\u001B[0m\n\u001B[0;32m     38\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttps://api.github.com/search/repositories?q=topic:\u001B[39m\u001B[38;5;132;01m{topic}\u001B[39;00m\u001B[38;5;124m&page=\u001B[39m\u001B[38;5;132;01m{page}\u001B[39;00m\u001B[38;5;124m&per_page=\u001B[39m\u001B[38;5;132;01m{per_page}\u001B[39;00m\u001B[38;5;124m&sort=stars&order=desc\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(topic\u001B[38;5;241m=\u001B[39mtopic, page \u001B[38;5;241m=\u001B[39m page,per_page \u001B[38;5;241m=\u001B[39m per_page)\n\u001B[0;32m     39\u001B[0m req \u001B[38;5;241m=\u001B[39m Request(url, headers\u001B[38;5;241m=\u001B[39mRepoHeaders)\n\u001B[1;32m---> 40\u001B[0m response \u001B[38;5;241m=\u001B[39m urlopen(req)\u001B[38;5;241m.\u001B[39mread()\n\u001B[0;32m     41\u001B[0m result \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(response\u001B[38;5;241m.\u001B[39mdecode())    \n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# 计算总条数以及总共需要请求的页数\u001B[39;00m\n",
      "File \u001B[1;32mD:\\python\\envs\\shiyuStudio\\Lib\\urllib\\request.py:215\u001B[0m, in \u001B[0;36murlopen\u001B[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001B[0m\n\u001B[0;32m    213\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    214\u001B[0m     opener \u001B[38;5;241m=\u001B[39m _opener\n\u001B[1;32m--> 215\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m opener\u001B[38;5;241m.\u001B[39mopen(url, data, timeout)\n",
      "File \u001B[1;32mD:\\python\\envs\\shiyuStudio\\Lib\\urllib\\request.py:521\u001B[0m, in \u001B[0;36mOpenerDirector.open\u001B[1;34m(self, fullurl, data, timeout)\u001B[0m\n\u001B[0;32m    519\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m processor \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprocess_response\u001B[38;5;241m.\u001B[39mget(protocol, []):\n\u001B[0;32m    520\u001B[0m     meth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(processor, meth_name)\n\u001B[1;32m--> 521\u001B[0m     response \u001B[38;5;241m=\u001B[39m meth(req, response)\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mD:\\python\\envs\\shiyuStudio\\Lib\\urllib\\request.py:630\u001B[0m, in \u001B[0;36mHTTPErrorProcessor.http_response\u001B[1;34m(self, request, response)\u001B[0m\n\u001B[0;32m    627\u001B[0m \u001B[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001B[39;00m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;66;03m# request was successfully received, understood, and accepted.\u001B[39;00m\n\u001B[0;32m    629\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m code \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m):\n\u001B[1;32m--> 630\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparent\u001B[38;5;241m.\u001B[39merror(\n\u001B[0;32m    631\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp\u001B[39m\u001B[38;5;124m'\u001B[39m, request, response, code, msg, hdrs)\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m response\n",
      "File \u001B[1;32mD:\\python\\envs\\shiyuStudio\\Lib\\urllib\\request.py:559\u001B[0m, in \u001B[0;36mOpenerDirector.error\u001B[1;34m(self, proto, *args)\u001B[0m\n\u001B[0;32m    557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m http_err:\n\u001B[0;32m    558\u001B[0m     args \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mdict\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp_error_default\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;241m+\u001B[39m orig_args\n\u001B[1;32m--> 559\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_chain(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[1;32mD:\\python\\envs\\shiyuStudio\\Lib\\urllib\\request.py:492\u001B[0m, in \u001B[0;36mOpenerDirector._call_chain\u001B[1;34m(self, chain, kind, meth_name, *args)\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m handler \u001B[38;5;129;01min\u001B[39;00m handlers:\n\u001B[0;32m    491\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(handler, meth_name)\n\u001B[1;32m--> 492\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs)\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    494\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32mD:\\python\\envs\\shiyuStudio\\Lib\\urllib\\request.py:639\u001B[0m, in \u001B[0;36mHTTPDefaultErrorHandler.http_error_default\u001B[1;34m(self, req, fp, code, msg, hdrs)\u001B[0m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mhttp_error_default\u001B[39m(\u001B[38;5;28mself\u001B[39m, req, fp, code, msg, hdrs):\n\u001B[1;32m--> 639\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(req\u001B[38;5;241m.\u001B[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001B[1;31mHTTPError\u001B[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "# 爬取官方topic下的所有仓库 日期2024/10/31\n",
    "govTopicFile = \"./topicPages/govTopics.txt\"\n",
    "repo_folder = \"./Repos\"\n",
    "with open(govTopicFile, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        govTopic = line.split(\":\")[1].strip()\n",
    "        folder_name = f\"{govTopic}\"\n",
    "        folder_path = os.path.join(repo_folder, folder_name)\n",
    "        os.makedirs(folder_path,exist_ok=True)\n",
    "        print(f\"新文件夹 `{folder_path}` 已创建\")\n",
    "        get_ReposByTopic(govTopic)\n",
    "        print(f\"{govTopic}的仓库信息已保存至: {folder_path}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T10:04:50.491388Z",
     "start_time": "2024-10-31T10:03:56.827284300Z"
    }
   },
   "id": "674f7588adaa9fac",
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "list = []\n",
    "topic = '3d'\n",
    "page = 1\n",
    "per_page = 100\n",
    "url = 'https://api.github.com/search/repositories?q=topic:{topic}&page={page}&per_page={per_page}&sort=stars&order=desc'.format(topic=topic, page = page,per_page = per_page)\n",
    "req = Request(url, headers=RepoHeaders)\n",
    "response = urlopen(req).read()\n",
    "result = json.loads(response.decode())\n",
    "print(len(result['items']))\n",
    "for item in result['items']:\n",
    "    list.append(item)\n",
    "\n",
    "total_count = result['total_count']\n",
    "\n",
    "# 封装成字典\n",
    "data_to_save = {'total_count': total_count, 'items': list}\n",
    "\n",
    "# 保存到本地 JSON 文件\n",
    "with open('items.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(data_to_save, json_file, ensure_ascii=False, indent=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T09:05:14.512692400Z",
     "start_time": "2024-10-31T09:05:11.356826800Z"
    }
   },
   "id": "a6e070c918a7747d",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./Reops\\java\n"
     ]
    }
   ],
   "source": [
    "repo_folder = \"./Reops\"\n",
    "folder_name = \"java\"\n",
    "folder_path = os.path.join(repo_folder, folder_name)\n",
    "print(folder_path)\n",
    "# os.makedirs(folder_path,exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-31T08:39:37.215160600Z",
     "start_time": "2024-10-31T08:39:37.209647300Z"
    }
   },
   "id": "2acc62b017f5ed75",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9dd01b53b0faa613"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
